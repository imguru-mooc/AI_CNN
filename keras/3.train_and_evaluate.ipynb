{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fb291b62b1aa"
   },
   "source": [
    "# Training and evaluation with the built-in methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8d4ac441b1fc"
   },
   "source": [
    "## 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:58:48.305955Z",
     "iopub.status.busy": "2021-04-07T17:58:48.305368Z",
     "iopub.status.idle": "2021-04-07T17:58:53.785129Z",
     "shell.execute_reply": "2021-04-07T17:58:53.785508Z"
    },
    "id": "0472bf67b2bf"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c16fe7fd6a6c"
   },
   "source": [
    "## 시작하기\n",
    "\n",
    "이 안내서는 훈련 및 유효성 검증을 위해 내장 API를 사용할 때의 훈련, 평가 및 예측 (추론) 모델 (예 : `model.fit()` , `model.evaluate()` , `model.predict()` )에 대해 설명합니다.\n",
    "\n",
    "고유한 훈련 단계 함수를 지정하면서 `fit()`을 사용하려면 <a href=\"https://www.tensorflow.org/guide/keras/customizing_what_happens_in_fit/\" data-md-type=\"link\">\" `fit()`에서 이루어지는 작업 사용자 정의하기\"</a> 가이드를 참조하세요.\n",
    "\n",
    "고유한 훈련 및 평가 루프를 처음부터 작성하려면 [\"처음부터 훈련 루프 작성\"](https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch/) 안내서를 참조하십시오.\n",
    "\n",
    "일반적으로, 내장 루프를 사용하든 직접 작성하든 관계없이 모델 훈련 및 유효성 검사는 모든 종류의 Keras 모델(순차 모델, Functional API로 작성된 모델 및 모델 하위 클래스화를 통해 처음부터 작성된 모델)에서 완전히 동일하게 작동합니다.\n",
    "\n",
    "이 가이드는 분산 교육에 대해서는 다루지 않습니다. 분산 교육에 대해서는 [멀티 GPU 및 분산 교육 안내서를](https://keras.io/guides/distributed_training/) 참조하십시오."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4e270faa413e"
   },
   "source": [
    "## API 개요 : 첫 번째 엔드 투 엔드 예제\n",
    "\n",
    "데이터를 모델의 내장 훈련 루프로 전달할 때는 **NumPy 배열**(데이터가 작고 메모리에 맞는 경우) 또는 **`tf.data Dataset` 객체**를 사용해야 합니다. 다음 몇 단락에서는 옵티마이저, 손실 및 메트릭을 사용하는 방법을 보여주기 위해 MNIST 데이터세트를 NumPy 배열로 사용하겠습니다.\n",
    "\n",
    "다음 모델을 고려해 보겠습니다 (여기서는 Functional API를 사용하여 빌드하지만 Sequential 모델 또는 하위 클래스 모델 일 수도 있음)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:58:53.792832Z",
     "iopub.status.busy": "2021-04-07T17:58:53.792213Z",
     "iopub.status.idle": "2021-04-07T17:58:55.407575Z",
     "shell.execute_reply": "2021-04-07T17:58:55.408010Z"
    },
    "id": "170a6a18b2a3"
   },
   "outputs": [],
   "source": [
    "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)         # (None,784)(784,64)\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)              # (None,64)(64,64)\n",
    "outputs = layers.Dense(10, activation=\"softmax\", name=\"predictions\")(x) # (None,64)(64,10)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e6d5724a90ab"
   },
   "source": [
    "일반적인 엔드 투 엔드 워크 플로는 다음과 같이 구성되어 있습니다.\n",
    "\n",
    "- 학습\n",
    "- 원래 교육 데이터에서 생성 된 홀드 아웃 세트에 대한 유효성 검사\n",
    "- 테스트 데이터에 대한 평가\n",
    "\n",
    "이 예에서는 MNIST 데이터를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:58:55.413652Z",
     "iopub.status.busy": "2021-04-07T17:58:55.413065Z",
     "iopub.status.idle": "2021-04-07T17:58:55.758213Z",
     "shell.execute_reply": "2021-04-07T17:58:55.757663Z"
    },
    "id": "8b55b3903edb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "(50000, 784)\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "print(type(x_train))\n",
    "# Preprocess the data (these are NumPy arrays)\n",
    "x_train = x_train.reshape(60000, 784).astype(\"float32\") / 255\n",
    "x_test = x_test.reshape(10000, 784).astype(\"float32\") / 255\n",
    "print(type(x_train))\n",
    "\n",
    "y_train = y_train.astype(\"float32\")\n",
    "y_test = y_test.astype(\"float32\")\n",
    "\n",
    "# Reserve 10,000 samples for validation\n",
    "x_val = x_train[-10000:]\n",
    "y_val = y_train[-10000:]\n",
    "x_train = x_train[:-10000]\n",
    "y_train = y_train[:-10000]\n",
    "print(type(x_train))\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "77a84eb1985b"
   },
   "source": [
    "훈련 구성(최적화 프로그램, 손실, 메트릭)을 지정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1]\n",
      "[ True False]\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "# keras.metrics.SparseCategoricalAccuracy()\n",
    "\n",
    "y_true = np.array([1, 2])\n",
    "y_pred = np.array([[0.1, 0.6, 0.3], \n",
    "                   [0.05, 0.95, 0]])\n",
    "\n",
    "sample_weight = [1, 2]\n",
    "\n",
    "print(np.argmax(y_pred, axis=1))\n",
    "print(np.equal(y_true, np.argmax(y_pred, axis=1)))\n",
    "acc = np.dot(sample_weight, np.equal(y_true, np.argmax(y_pred, axis=1)))\n",
    "print(acc/2.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n",
      "0.7\n"
     ]
    }
   ],
   "source": [
    "m = tf.keras.metrics.SparseCategoricalAccuracy()\n",
    "m.update_state([[2], [1]], [[0.1, 0.6, 0.3], [0.05, 0.95, 0]])\n",
    "print(m.result().numpy())\n",
    "\n",
    "\n",
    "m.reset_state()\n",
    "m.update_state([[1], [2]], [[0.1, 0.6, 0.3], [0.05, 0.95, 0]],\n",
    "                sample_weight=[0.7, 0.3])\n",
    "print(m.result().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:58:55.769921Z",
     "iopub.status.busy": "2021-04-07T17:58:55.769317Z",
     "iopub.status.idle": "2021-04-07T17:58:55.788128Z",
     "shell.execute_reply": "2021-04-07T17:58:55.787601Z"
    },
    "id": "26a7f1819796"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(),  # Optimizer\n",
    "    # Loss function to minimize\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    # List of metrics to monitor\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ef28150b1eaa"
   },
   "source": [
    "`fit()`를 호출하여 데이터를 \"batch_size\" 크기의 \"배치\"로 분할하고 지정된 수의 \"epoch\"에 대해 전체 데이터세트를 반복 처리하여 모델을 훈련시킵니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:58:55.792862Z",
     "iopub.status.busy": "2021-04-07T17:58:55.792230Z",
     "iopub.status.idle": "2021-04-07T17:59:00.616809Z",
     "shell.execute_reply": "2021-04-07T17:59:00.617243Z"
    },
    "id": "0b92f67b105e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit model on training data\n",
      "<class 'numpy.ndarray'>\n",
      "Epoch 1/2\n",
      "782/782 [==============================] - 6s 6ms/step - loss: 0.3270 - sparse_categorical_accuracy: 0.9061 - val_loss: 0.1702 - val_sparse_categorical_accuracy: 0.9495\n",
      "Epoch 2/2\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1550 - sparse_categorical_accuracy: 0.9533 - val_loss: 0.1211 - val_sparse_categorical_accuracy: 0.9638\n"
     ]
    }
   ],
   "source": [
    "print(\"Fit model on training data\")\n",
    "print(type(x_train))\n",
    "history = model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    batch_size=64,\n",
    "    epochs=2,\n",
    "    # We pass some validation for\n",
    "    # monitoring validation loss and metrics\n",
    "    # at the end of each epoch\n",
    "    validation_data=(x_val, y_val),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0a1b698c6e39"
   },
   "source": [
    "반환되는 \"이력\" 객체는 훈련 중 손실 값과 메트릭 값에 대한 레코드를 유지합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:00.625752Z",
     "iopub.status.busy": "2021-04-07T17:59:00.625141Z",
     "iopub.status.idle": "2021-04-07T17:59:00.628091Z",
     "shell.execute_reply": "2021-04-07T17:59:00.628463Z"
    },
    "id": "a20b8f5b9fcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.3269665539264679, 0.15500539541244507],\n",
       " 'sparse_categorical_accuracy': [0.9060800075531006, 0.9532600045204163],\n",
       " 'val_loss': [0.17024099826812744, 0.12112268060445786],\n",
       " 'val_sparse_categorical_accuracy': [0.9495000243186951, 0.9638000130653381]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6105b646df66"
   },
   "source": [
    "`evaluate()`를 통해 테스트 데이터에 대해 모델을 평가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:00.632994Z",
     "iopub.status.busy": "2021-04-07T17:59:00.632410Z",
     "iopub.status.idle": "2021-04-07T17:59:00.894621Z",
     "shell.execute_reply": "2021-04-07T17:59:00.894161Z"
    },
    "id": "69f524a93f9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on test data\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1261 - sparse_categorical_accuracy: 0.9607\n",
      "test loss, test acc: [0.12614674866199493, 0.9606999754905701]\n",
      "Generate predictions for 3 samples\n",
      "predictions shape: (3, 10)\n",
      "[[3.12545058e-06 5.45527179e-08 4.53643705e-04 4.18573880e-04\n",
      "  4.35686900e-08 1.80795462e-06 5.80570481e-10 9.99065697e-01\n",
      "  7.50798051e-07 5.63545800e-05]\n",
      " [1.06801572e-07 2.96770385e-03 9.94909465e-01 1.99494511e-03\n",
      "  1.97293584e-10 2.05649576e-05 1.65830465e-06 6.15925231e-08\n",
      "  1.05501196e-04 4.42291898e-11]\n",
      " [4.98647896e-05 9.92045045e-01 1.57396926e-03 1.26971281e-03\n",
      "  3.04634741e-04 4.94794571e-04 5.52182202e-04 2.42698728e-03\n",
      "  1.12744048e-03 1.55379996e-04]]\n",
      "[1.0000001 1.0000001 1.       ]\n",
      "[7 2 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# Evaluate the model on the test data using `evaluate`\n",
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(x_test, y_test, batch_size=128)\n",
    "print(\"test loss, test acc:\", results)\n",
    "\n",
    "# Generate predictions (probabilities -- the output of the last layer)\n",
    "# on new data using `predict`\n",
    "print(\"Generate predictions for 3 samples\")\n",
    "predictions = model.predict(x_test[:3])\n",
    "print(\"predictions shape:\", predictions.shape)\n",
    "print(predictions)\n",
    "print(np.sum(predictions, axis=1))\n",
    "print(np.argmax(predictions, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f19d074eb88c"
   },
   "source": [
    "이제이 워크 플로의 각 부분을 자세히 검토하겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f3669f026d14"
   },
   "source": [
    "## `compile()` 메소드 : 손실, 메트릭 및 최적화 프로그램 지정\n",
    "\n",
    "`fit()` 으로 모델을 학습하려면 손실 함수, 최적화 프로그램 및 선택적으로 모니터링 할 일부 메트릭을 지정해야합니다.\n",
    "\n",
    "이것을 `compile()` 메소드의 인수로 모델에 전달합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:00.903471Z",
     "iopub.status.busy": "2021-04-07T17:59:00.902774Z",
     "iopub.status.idle": "2021-04-07T17:59:00.912104Z",
     "shell.execute_reply": "2021-04-07T17:59:00.911681Z"
    },
    "id": "eb7a8deb494c"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(learning_rate=1e-3),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[keras.metrics.SparseCategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c4061c977ac3"
   },
   "source": [
    "`metrics` 인수는 목록이어야합니다. 모델에는 여러 개의 메트릭이있을 수 있습니다.\n",
    "\n",
    "모델에 여러 개의 출력이있는 경우 각 출력에 대해 서로 다른 손실 및 메트릭을 지정하고 모델의 총 손실에 대한 각 출력의 기여도를 조정할 수 있습니다. 이에 대한 자세한 내용은 **\"다중 입력, 다중 출력 모델로 데이터 전달\"** 섹션에서 확인할 수 있습니다.\n",
    "\n",
    "기본 설정에 만족하면 대부분의 경우 최적화, 손실 및 메트릭을 문자열 식별자를 통해 바로 가기로 지정할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:00.920513Z",
     "iopub.status.busy": "2021-04-07T17:59:00.919946Z",
     "iopub.status.idle": "2021-04-07T17:59:00.924629Z",
     "shell.execute_reply": "2021-04-07T17:59:00.924967Z"
    },
    "id": "6444839ff300"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=\"rmsprop\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"sparse_categorical_accuracy\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5493ab963254"
   },
   "source": [
    "나중에 재사용하기 위해 모델 정의와 컴파일 단계를 함수에 넣겠습니다. 이 안내서의 여러 예에서 여러 번 호출합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:00.930518Z",
     "iopub.status.busy": "2021-04-07T17:59:00.929926Z",
     "iopub.status.idle": "2021-04-07T17:59:00.932021Z",
     "shell.execute_reply": "2021-04-07T17:59:00.931520Z"
    },
    "id": "31c3e3c70f06"
   },
   "outputs": [],
   "source": [
    "def get_uncompiled_model():\n",
    "    inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "    x = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "    x = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "    outputs = layers.Dense(10, activation=\"softmax\", name=\"predictions\")(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_compiled_model():\n",
    "    model = get_uncompiled_model()\n",
    "    model.compile(\n",
    "        optimizer=\"rmsprop\",\n",
    "        loss=\"sparse_categorical_crossentropy\",\n",
    "        metrics=[\"sparse_categorical_accuracy\"],\n",
    "    )\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "21b19c0a6a85"
   },
   "source": [
    "### 많은 내장 옵티 마이저, 손실 및 메트릭을 사용할 수 있습니다\n",
    "\n",
    "일반적으로 고유한 손실, 메트릭 또는 최적화 프로그램을 처음부터 새로 만들 필요가 없는데, Keras API에 필요한 것들이 이미 들어 있을 개연성이 높기 때문입니다.\n",
    "\n",
    "옵티마이저\n",
    "\n",
    "- `SGD()` (모멘텀이 있거나 없음)\n",
    "- `RMSprop()`\n",
    "- `Adam()`\n",
    "- 기타\n",
    "\n",
    "손실:\n",
    "\n",
    "- `MeanSquaredError()`\n",
    "- `KLDivergence()`\n",
    "- `CosineSimilarity()`\n",
    "- 기타\n",
    "\n",
    "메트릭\n",
    "\n",
    "- `AUC()`\n",
    "- `Precision()`\n",
    "- `Recall()`\n",
    "- 기타"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d7abc0339980"
   },
   "source": [
    "### 관례 손실\n",
    "\n",
    "Keras로 커스텀 손실을 제공하는 두 가지 방법이 있습니다. 첫 번째 예는 입력 `y_true` 및 `y_pred` 를 받아들이는 함수를 만듭니다. 다음 예는 실제 데이터와 예측 간의 평균 제곱 오차를 계산하는 손실 함수를 보여줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function foo at 0x000001A5FC975550>\n",
      "<function foo at 0x000001A5FC975550>\n",
      "foo()\n",
      "foo()\n"
     ]
    }
   ],
   "source": [
    "def foo():\n",
    "    print('foo()')\n",
    "\n",
    "loss = foo\n",
    "print(foo)\n",
    "print(loss)\n",
    "foo()\n",
    "loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:00.938634Z",
     "iopub.status.busy": "2021-04-07T17:59:00.938085Z",
     "iopub.status.idle": "2021-04-07T17:59:02.545087Z",
     "shell.execute_reply": "2021-04-07T17:59:02.544610Z"
    },
    "id": "cc4edd47bb5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 784)\n",
      "Tensor(\"IteratorGetNext:1\", shape=(None, 10), dtype=float32) Tensor(\"model_3/predictions/Softmax:0\", shape=(None, 10), dtype=float32)\n",
      "Tensor(\"IteratorGetNext:1\", shape=(None, 10), dtype=float32) Tensor(\"model_3/predictions/Softmax:0\", shape=(None, 10), dtype=float32)\n",
      "782/782 [==============================] - 2s 3ms/step - loss: 0.0156\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1abaca97100>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "def custom_mean_squared_error(y_true, y_pred):\n",
    "    print(y_true, y_pred)\n",
    "    return tf.math.reduce_mean(tf.square(y_true - y_pred))\n",
    "\n",
    "\n",
    "model = get_uncompiled_model()\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss=custom_mean_squared_error)\n",
    "\n",
    "# We need to one-hot encode the labels to use MSE\n",
    "y_train_one_hot = tf.one_hot(y_train, depth=10)\n",
    "model.fit(x_train, y_train_one_hot, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "25b9fa7941ca"
   },
   "source": [
    "`y_true` 및 `y_pred` 이외의 매개 변수를 사용하는 손실 함수가 필요한 경우 `tf.keras.losses.Loss` 클래스를 서브 클래스 화하고 다음 두 메소드를 구현할 수 있습니다.\n",
    "\n",
    "- `__init__(self)` : 손실 함수 호출 중에 전달할 매개 변수를 승인합니다.\n",
    "- `call(self, y_true, y_pred)` : 목표 (y_true)와 모델 예측 (y_pred)을 사용하여 모델의 손실을 계산\n",
    "\n",
    "평균 제곱 오차를 사용하려고하지만 예측 값을 0.5에서 멀어지게하는 용어가 추가되었다고 가정 해 보겠습니다 (우리는 범주 형 목표가 원-핫 인코딩되고 0과 1 사이의 값을 취하는 것으로 가정). 이렇게하면 모델이 너무 자신감이없는 인센티브가 생겨 과적 합을 줄이는 데 도움이 될 수 있습니다 (시도 할 때까지 작동하는지 알 수 없음).\n",
    "\n",
    "방법은 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "foo.call()\n"
     ]
    }
   ],
   "source": [
    "class Parent:\n",
    "    def __call__(self):\n",
    "        self.call()\n",
    "\n",
    "class foo(Parent):\n",
    "    def call(self):\n",
    "        print(\"foo.call()\")\n",
    "        \n",
    "foo()()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:02.553096Z",
     "iopub.status.busy": "2021-04-07T17:59:02.552526Z",
     "iopub.status.idle": "2021-04-07T17:59:04.353462Z",
     "shell.execute_reply": "2021-04-07T17:59:04.353833Z"
    },
    "id": "b09463a8c568"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 3s 3ms/step - loss: 0.0385\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1abb3b7a3d0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CustomMSE(keras.losses.Loss):\n",
    "    def __init__(self, regularization_factor=0.1, name=\"custom_mse\"):\n",
    "        super().__init__(name=name)\n",
    "        self.regularization_factor = regularization_factor\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        mse = tf.math.reduce_mean(tf.square(y_true - y_pred))\n",
    "        reg = tf.math.reduce_mean(tf.square(0.5 - y_pred))\n",
    "        return mse + reg * self.regularization_factor\n",
    "\n",
    "\n",
    "model = get_uncompiled_model()\n",
    "model.compile(optimizer=keras.optimizers.Adam(), loss=CustomMSE(0.1))  # loss(y_true, y_pred)\n",
    "\n",
    "y_train_one_hot = tf.one_hot(y_train, depth=10)\n",
    "model.fit(x_train, y_train_one_hot, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b2141cc075a6"
   },
   "source": [
    "### 맞춤 측정 항목\n",
    "\n",
    "API의 일부가 아닌 메트릭이 필요한 경우 `tf.keras.metrics.Metric` 클래스를 서브 클래 싱하여 사용자 지정 메트릭을 쉽게 만들 수 있습니다. 4 가지 방법을 구현해야합니다.\n",
    "\n",
    "- `__init__(self)` . 여기서 메트릭에 대한 상태 변수를 만듭니다.\n",
    "- `update_state(self, y_true, y_pred, sample_weight=None)` 대상 y_true 및 모델 예측 y_pred를 사용하여 상태 변수를 업데이트합니다.\n",
    "- `result(self)` : 상태 변수를 사용하여 최종 결과를 계산합니다.\n",
    "- `reset_states(self)` : 메트릭의 상태를 다시 초기화합니다.\n",
    "\n",
    "경우에 따라 결과 계산이 매우 비싸고 주기적으로 만 수행되기 때문에 상태 업데이트와 결과 계산은 각각 `update_state()` 와 `result()` 에서 별도로 유지됩니다.\n",
    "\n",
    "다음은 `CategoricalTruePositives` 메트릭을 구현하는 방법을 보여주는 간단한 예제입니다.이 메트릭은 주어진 클래스에 속하는 것으로 올바르게 분류 된 샘플 수를 계산합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:04.363314Z",
     "iopub.status.busy": "2021-04-07T17:59:04.362654Z",
     "iopub.status.idle": "2021-04-07T17:59:09.979834Z",
     "shell.execute_reply": "2021-04-07T17:59:09.980190Z"
    },
    "id": "05d6a6e7022d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3430 - categorical_true_positives: 45080.0000\n",
      "Epoch 2/3\n",
      " 31/782 [>.............................] - ETA: 3s - loss: 0.1781 - categorical_true_positives: 1883.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jikim\\anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\metrics.py:254: UserWarning: Metric CategoricalTruePositives implements a `reset_states()` method; rename it to `reset_state()` (without the final \"s\"). The name `reset_states()` has been deprecated to improve API consistency.\n",
      "  warnings.warn('Metric %s implements a `reset_states()` method; rename it '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1602 - categorical_true_positives: 47603.0000\n",
      "Epoch 3/3\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1174 - categorical_true_positives: 48226.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1abba539a60>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CategoricalTruePositives(keras.metrics.Metric):\n",
    "    def __init__(self, name=\"categorical_true_positives\", **kwargs):\n",
    "        super(CategoricalTruePositives, self).__init__(name=name, **kwargs)\n",
    "        self.true_positives = self.add_weight(name=\"ctp\", initializer=\"zeros\")\n",
    "\n",
    "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
    "        y_pred = tf.reshape(tf.argmax(y_pred, axis=1), shape=(-1, 1))\n",
    "        values = tf.cast(y_true, \"int32\") == tf.cast(y_pred, \"int32\")\n",
    "        values = tf.cast(values, \"float32\")\n",
    "        if sample_weight is not None:\n",
    "            sample_weight = tf.cast(sample_weight, \"float32\")\n",
    "            values = tf.multiply(values, sample_weight)\n",
    "        self.true_positives.assign_add(tf.reduce_sum(values))\n",
    "\n",
    "    def result(self):\n",
    "        return self.true_positives\n",
    "\n",
    "    def reset_states(self):\n",
    "        # The state of the metric will be reset at the start of each epoch.\n",
    "        self.true_positives.assign(0.0)\n",
    "\n",
    "\n",
    "model = get_uncompiled_model()\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(learning_rate=1e-3),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[CategoricalTruePositives()],\n",
    ")\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4bca8e959cda"
   },
   "source": [
    "### 표준 서명에 맞지 않는 손실 및 메트릭 처리하기\n",
    "\n",
    "거의 대부분의 손실과 메트릭은 `y_true` 및 `y_pred`에서 계산할 수 있습니다(여기서 `y_pred`가 모델의 출력). 그러나 모두가 그런 것은 아닙니다. 예를 들어, 정규화 손실은 레이어의 활성화만 요구할 수 있으며(이 경우 대상이 없음) 이 활성화는 모델 출력이 아닐 수 있습니다.\n",
    "\n",
    "이러한 경우 사용자 정의 레이어의 호출 메서드 내에서 `self.add_loss(loss_value)`를 호출할 수 있습니다. 이러한 방식으로 추가된 손실은 훈련 중 \"주요\" 손실(`compile()`로 전달되는 손실)에 추가됩니다. 다음은 활동 정규화를 추가하는 간단한 예입니다. 참고로 활동 정규화는 모든 Keras 레이어에 내장되어 있으며 이 레이어는 구체적인 예를 제공하기 위한 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:09.989008Z",
     "iopub.status.busy": "2021-04-07T17:59:09.988416Z",
     "iopub.status.idle": "2021-04-07T17:59:12.011691Z",
     "shell.execute_reply": "2021-04-07T17:59:12.011174Z"
    },
    "id": "b494d47437a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 4s 5ms/step - loss: 2.5210\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1abd75f4e20>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ActivityRegularizationLayer(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        self.add_loss(tf.reduce_sum(inputs) * 0.1)\n",
    "        return inputs  # Pass-through layer.\n",
    "\n",
    "\n",
    "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)  # (None,784)(784,64)\n",
    "\n",
    "# Insert activity regularization as a layer\n",
    "x = ActivityRegularizationLayer()(x)   # (None,64)\n",
    "\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "outputs = layers.Dense(10, name=\"predictions\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(learning_rate=1e-3),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    ")\n",
    "\n",
    "# The displayed loss will be much higher than before\n",
    "# due to the regularization component.\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aaebb5829011"
   },
   "source": [
    "`add_metric()` 사용하여 메트릭 값 로깅에 대해 동일한 작업을 수행 할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.8164966, shape=(), dtype=float32)\n",
      "0.8164966\n"
     ]
    }
   ],
   "source": [
    "x = tf.constant([1,2,3], dtype=float)\n",
    "print(keras.backend.std(x))\n",
    "print(np.std(x.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:12.021377Z",
     "iopub.status.busy": "2021-04-07T17:59:12.019956Z",
     "iopub.status.idle": "2021-04-07T17:59:14.167067Z",
     "shell.execute_reply": "2021-04-07T17:59:14.167421Z"
    },
    "id": "aa58091be092"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3327 - std_of_activation: 0.9534\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1abe01d3430>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MetricLoggingLayer(layers.Layer):\n",
    "    def call(self, inputs):\n",
    "        # The `aggregation` argument defines\n",
    "        # how to aggregate the per-batch values\n",
    "        # over each epoch:\n",
    "        # in this case we simply average them.\n",
    "        self.add_metric(\n",
    "            keras.backend.std(inputs), name=\"std_of_activation\", aggregation=\"mean\"\n",
    "        )\n",
    "        return inputs  # Pass-through layer.\n",
    "\n",
    "\n",
    "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "\n",
    "# Insert std logging as a layer.\n",
    "x = MetricLoggingLayer()(x)\n",
    "\n",
    "x = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "outputs = layers.Dense(10, name=\"predictions\")(x)\n",
    "\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(learning_rate=1e-3),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    ")\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f3c18154d057"
   },
   "source": [
    "[Functional API](https://www.tensorflow.org/guide/keras/functional/) 에서 `model.add_loss(loss_tensor)` 또는 `model.add_metric(metric_tensor, name, aggregation)` 호출 할 수도 있습니다.\n",
    "\n",
    "다음은 간단한 예입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:14.176154Z",
     "iopub.status.busy": "2021-04-07T17:59:14.175268Z",
     "iopub.status.idle": "2021-04-07T17:59:16.355388Z",
     "shell.execute_reply": "2021-04-07T17:59:16.354905Z"
    },
    "id": "0e19afe78b3a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 4s 5ms/step - loss: 2.5473 - std_of_activation: 0.0021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1abe5f62190>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(784,), name=\"digits\")\n",
    "x1 = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "x2 = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x1)\n",
    "outputs = layers.Dense(10, name=\"predictions\")(x2)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "model.add_loss(tf.reduce_sum(x1) * 0.1)\n",
    "\n",
    "model.add_metric(keras.backend.std(x1), name=\"std_of_activation\", aggregation=\"mean\")\n",
    "\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    ")\n",
    "model.fit(x_train, y_train, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b06d48035369"
   },
   "source": [
    "`add_loss()` 를 통해 손실을 전달하면 모델에는 이미 손실이 있으므로 손실 함수없이 `compile()` 을 호출 할 수 있습니다.\n",
    "\n",
    "다음 `LogisticEndpoint` 레이어를 생각해 보겠습니다. 이 레이어는 입력으로 targets 및 logits를 받아들이고 `add_loss()`를 통해 교차 엔트로피 손실을 추적합니다. 또한 `add_metric()`를 통해 분류 정확도도 추적합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:16.361776Z",
     "iopub.status.busy": "2021-04-07T17:59:16.361194Z",
     "iopub.status.idle": "2021-04-07T17:59:16.362990Z",
     "shell.execute_reply": "2021-04-07T17:59:16.363332Z"
    },
    "id": "d56d2c504258"
   },
   "outputs": [],
   "source": [
    "class LogisticEndpoint(keras.layers.Layer):\n",
    "    def __init__(self, name=None):\n",
    "        super(LogisticEndpoint, self).__init__(name=name)\n",
    "        self.loss_fn = keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "        self.accuracy_fn = keras.metrics.BinaryAccuracy()\n",
    "\n",
    "    def call(self, targets, logits, sample_weights=None):\n",
    "        # Compute the training-time loss value and add it\n",
    "        # to the layer using `self.add_loss()`.\n",
    "        loss = self.loss_fn(targets, logits, sample_weights)\n",
    "        self.add_loss(loss)\n",
    "\n",
    "        # Log accuracy as a metric and add it\n",
    "        # to the layer using `self.add_metric()`.\n",
    "        acc = self.accuracy_fn(targets, logits, sample_weights)\n",
    "        self.add_metric(acc, name=\"accuracy\")\n",
    "\n",
    "        # Return the inference-time prediction tensor (for `.predict()`).\n",
    "        return tf.nn.softmax(logits)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0698f3c98cbe"
   },
   "source": [
    "다음과 같이 `loss` 인수없이 컴파일 된 두 개의 입력 (입력 데이터 및 대상)이있는 모델에서 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:16.372039Z",
     "iopub.status.busy": "2021-04-07T17:59:16.370993Z",
     "iopub.status.idle": "2021-04-07T17:59:16.746912Z",
     "shell.execute_reply": "2021-04-07T17:59:16.747257Z"
    },
    "id": "0f6842f2bbe6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 143ms/step - loss: 0.9975 - binary_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1abe7551820>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "inputs = keras.Input(shape=(3,), name=\"inputs\")\n",
    "targets = keras.Input(shape=(10,), name=\"targets\")\n",
    "logits = keras.layers.Dense(10)(inputs)\n",
    "predictions = LogisticEndpoint(name=\"predictions\")(logits, targets)\n",
    "\n",
    "model = keras.Model(inputs=[inputs, targets], outputs=predictions)\n",
    "model.compile(optimizer=\"adam\")  # No loss argument!\n",
    "\n",
    "data = {\n",
    "    \"inputs\": np.random.random((3, 3)),\n",
    "    \"targets\": np.random.random((3, 10)),\n",
    "}\n",
    "model.fit(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "328b021aa6b8"
   },
   "source": [
    "다중 입력 모델 교육에 대한 자세한 내용은 **다중 입력, 다중 출력 모델로 데이터 전달** 섹션을 참조하십시오."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0536882b969c"
   },
   "source": [
    "### 유효성 검사 홀드아웃 세트를 자동으로 분리하기\n",
    "\n",
    "본 첫 번째 엔드 투 엔드 예제에서, 우리는 `validation_data` 인수를 사용하여 NumPy 배열의 튜플 `(x_val, y_val)` 을 모델에 전달하여 각 에포크의 끝에서 유효성 검증 손실 및 유효성 검증 메트릭을 평가합니다.\n",
    "\n",
    "또 다른 옵션: 인수 `validation_split`를 사용하여 유효성 검사 목적으로 훈련 데이터의 일부를 자동으로 예약할 수 있습니다. 인수 값은 유효성 검사를 위해 예약할 데이터 비율을 나타내므로 0보다 크고 1보다 작은 값으로 설정해야 합니다. 예를 들어, `validation_split=0.2`는 \"유효성 검사를 위해 데이터의 20%를 사용\"한다는 의미이고`validation_split=0.6`은 \"유효성 검사를 위해 데이터의 60%를 사용\"한다는 의미입니다.\n",
    "\n",
    "유효성을 계산하는 방법은 셔플 링 전에 맞춤 호출로 수신 한 배열의 마지막 x % 샘플을 가져 오는 것입니다.\n",
    "\n",
    "NumPy 데이터를 학습 할 때 `validation_split` 만 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:16.754009Z",
     "iopub.status.busy": "2021-04-07T17:59:16.753094Z",
     "iopub.status.idle": "2021-04-07T17:59:18.729991Z",
     "shell.execute_reply": "2021-04-07T17:59:18.729293Z"
    },
    "id": "232fd59c751b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "625/625 [==============================] - 4s 6ms/step - loss: 0.3683 - sparse_categorical_accuracy: 0.8953 - val_loss: 0.2263 - val_sparse_categorical_accuracy: 0.9320\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1abee397f10>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "model.fit(x_train, y_train, batch_size=64, validation_split=0.2, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "42969af7ce01"
   },
   "source": [
    "## tf.data 데이터 세트의 교육 및 평가\n",
    "\n",
    "앞서 몇 단락에 걸쳐 손실, 메트릭 및 옵티마이저를 처리하는 방법을 살펴보았으며, 데이터가 NumPy 배열로 전달될 때 fit에서 `validation_data` 및 `validation_split` 인수를 사용하는 방법도 알아보았습니다.\n",
    "\n",
    "이제 데이터가 `tf.data.Dataset` 객체의 형태로 제공되는 경우를 살펴 보겠습니다.\n",
    "\n",
    "`tf.data` API는 빠르고 확장 가능한 방식으로 데이터를 로드하고 사전 처리하기 위한 TensorFlow 2.0의 유틸리티 세트입니다.\n",
    "\n",
    "`Datasets` 생성에 대한 자세한 설명은 [tf.data 설명서](https://www.tensorflow.org/guide/data)를 참조하세요.\n",
    "\n",
    "`Dataset` 인스턴스를 메서드 `fit()`, `evaluate()` 및 `predict()`로 직접 전달할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:18.737374Z",
     "iopub.status.busy": "2021-04-07T17:59:18.736671Z",
     "iopub.status.idle": "2021-04-07T17:59:25.389166Z",
     "shell.execute_reply": "2021-04-07T17:59:25.388563Z"
    },
    "id": "3bf4ded224f8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3479 - sparse_categorical_accuracy: 0.9002\n",
      "Epoch 2/3\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1677 - sparse_categorical_accuracy: 0.9508\n",
      "Epoch 3/3\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1219 - sparse_categorical_accuracy: 0.9635\n",
      "Evaluate\n",
      "157/157 [==============================] - 0s 2ms/step - loss: 0.1151 - sparse_categorical_accuracy: 0.9663\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.115113265812397, 'sparse_categorical_accuracy': 0.9663000106811523}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "\n",
    "# First, let's create a training Dataset instance.\n",
    "# For the sake of our example, we'll use the same MNIST data as before.\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "# Shuffle and slice the dataset.\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "# Now we get a test dataset.\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "test_dataset = test_dataset.batch(64)\n",
    "\n",
    "# Since the dataset already takes care of batching,\n",
    "# we don't pass a `batch_size` argument.\n",
    "model.fit(train_dataset, epochs=3)\n",
    "\n",
    "# You can also evaluate or predict on a dataset.\n",
    "print(\"Evaluate\")\n",
    "result = model.evaluate(test_dataset)\n",
    "dict(zip(model.metrics_names, result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "421d16914ce3"
   },
   "source": [
    "데이터세트는 각 epoch의 끝에서 재설정되므로 다음 epoch에서 재사용할 수 있습니다.\n",
    "\n",
    "이 데이터세트의 특정 배치 수에 대해서만 훈련을 실행하려면 다음 epoch로 이동하기 전에 이 데이터세트를 사용하여 모델이 실행해야 하는 훈련 단계의 수를 지정하는 `steps_per_epoch` 인수를 전달할 수 있습니다.\n",
    "\n",
    "이렇게 하면 각 epoch가 끝날 때 데이터세트가 재설정되지 않고 다음 배치를 계속 가져오게 됩니다. 무한 반복되는 데이터세트가 아니라면 결국 데이터세트의 데이터가 고갈됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:25.395575Z",
     "iopub.status.busy": "2021-04-07T17:59:25.394783Z",
     "iopub.status.idle": "2021-04-07T17:59:26.675941Z",
     "shell.execute_reply": "2021-04-07T17:59:26.675448Z"
    },
    "id": "273c5dff16b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "100/100 [==============================] - 1s 6ms/step - loss: 0.7999 - sparse_categorical_accuracy: 0.7919\n",
      "Epoch 2/3\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.3788 - sparse_categorical_accuracy: 0.8930\n",
      "Epoch 3/3\n",
      "100/100 [==============================] - 0s 4ms/step - loss: 0.3163 - sparse_categorical_accuracy: 0.9075\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1abf2f32c70>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "\n",
    "# Prepare the training dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "# Only use the 100 batches per epoch (that's 64 * 100 samples)\n",
    "model.fit(train_dataset, epochs=3, steps_per_epoch=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2dcd180da7b"
   },
   "source": [
    "### 유효성 검사 데이터 집합 사용\n",
    "\n",
    "`fit()` 에서 `Dataset` 인스턴스를 `validation_data` 인수로 전달할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:26.682749Z",
     "iopub.status.busy": "2021-04-07T17:59:26.681981Z",
     "iopub.status.idle": "2021-04-07T17:59:29.751000Z",
     "shell.execute_reply": "2021-04-07T17:59:29.751364Z"
    },
    "id": "bf4f3d78e69a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3398 - sparse_categorical_accuracy: 0.9035 - val_loss: 0.1851 - val_sparse_categorical_accuracy: 0.9500\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1622 - sparse_categorical_accuracy: 0.9519 - val_loss: 0.1332 - val_sparse_categorical_accuracy: 0.9624\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.1204 - sparse_categorical_accuracy: 0.9645 - val_loss: 0.1255 - val_sparse_categorical_accuracy: 0.9645\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.0954 - sparse_categorical_accuracy: 0.9713 - val_loss: 0.1098 - val_sparse_categorical_accuracy: 0.9701\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.0805 - sparse_categorical_accuracy: 0.9763 - val_loss: 0.1060 - val_sparse_categorical_accuracy: 0.9699\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.0675 - sparse_categorical_accuracy: 0.9793 - val_loss: 0.1028 - val_sparse_categorical_accuracy: 0.9724\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.0587 - sparse_categorical_accuracy: 0.9826 - val_loss: 0.1065 - val_sparse_categorical_accuracy: 0.9725\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.0519 - sparse_categorical_accuracy: 0.9846 - val_loss: 0.0994 - val_sparse_categorical_accuracy: 0.9737\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.0442 - sparse_categorical_accuracy: 0.9873 - val_loss: 0.1032 - val_sparse_categorical_accuracy: 0.9734\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.0394 - sparse_categorical_accuracy: 0.9888 - val_loss: 0.1287 - val_sparse_categorical_accuracy: 0.9681\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1abf87cea90>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "\n",
    "# Prepare the training dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "# Prepare the validation dataset\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "val_dataset = val_dataset.batch(64)\n",
    "\n",
    "model.fit(train_dataset, epochs=10, validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2e7f0ebf5f1d"
   },
   "source": [
    "각 시대가 끝날 때 모델은 유효성 검사 데이터 집합을 반복하고 유효성 검사 손실 및 유효성 검사 메트릭을 계산합니다.\n",
    "\n",
    "이 데이터세트의 특정 배치 수에 대해서만 유효성 검사를 실행하려면 유효성 검사를 중단하고 다음 epoch로 넘어가기 전에 유효성 검사 데이터세트에서 모델이 실행해야 하는 유효성 검사 단계의 수를 지정하는 `validation_steps` 인수를 전달할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:29.758316Z",
     "iopub.status.busy": "2021-04-07T17:59:29.757458Z",
     "iopub.status.idle": "2021-04-07T17:59:32.372341Z",
     "shell.execute_reply": "2021-04-07T17:59:32.372720Z"
    },
    "id": "f47342fed069"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3328 - sparse_categorical_accuracy: 0.9052 - val_loss: 0.2699 - val_sparse_categorical_accuracy: 0.9297\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1abf87ce700>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "\n",
    "# Prepare the training dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "# Prepare the validation dataset\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val))\n",
    "val_dataset = val_dataset.batch(64)\n",
    "\n",
    "model.fit(\n",
    "    train_dataset,\n",
    "    epochs=1,\n",
    "    # Only run validation using the first 10 batches of the dataset\n",
    "    # using the `validation_steps` argument\n",
    "    validation_data=val_dataset,\n",
    "    validation_steps=10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "67b4418e9f26"
   },
   "source": [
    "유효성 검사 데이터 세트는 사용 후마다 재설정되므로 항상 에포크에서 에포크까지 동일한 샘플을 평가하게됩니다.\n",
    "\n",
    "인수 `validation_split`(훈련 데이터로부터 홀드아웃 세트 생성)는 `Dataset` 객체로 훈련할 때는 지원되지 않는데, 이를 위해서는 데이터세트 샘플을 인덱싱할 수 있어야 하지만 `Dataset` API에서는 일반적으로 이것이 불가능하기 때문입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8160beb766a0"
   },
   "source": [
    "## 지원되는 다른 입력 형식\n",
    "\n",
    "NumPy 배열, 즉시 실행 텐서 및 TensorFlow `Datasets` 외에도 Pandas 데이터프레임을 사용하거나 데이터 및 레이블의 배치를 생성하는 Python 생성기에서 Keras 모델을 훈련할 수 있습니다.\n",
    "\n",
    "특히, `keras.utils.Sequence` 클래스는 멀티스레딩을 인식하고 셔플이 가능한 Python 데이터 생성기를 빌드하기 위한 간단한 인터페이스를 제공합니다.\n",
    "\n",
    "일반적으로 다음을 사용하는 것이 좋습니다.\n",
    "\n",
    "- 데이터가 작고 메모리에 맞는 경우 NumPy 입력 데이터\n",
    "- 큰 데이터세트가 있고 분산 훈련을 수행해야 하는 경우 `Dataset` 객체\n",
    "- 큰 데이터세트가 있고 TensorFlow에서 수행할 수 없는 많은 사용자 정의 Python 측 처리를 수행해야 하는 경우(예: 데이터 로드 또는 사전 처리를 위해 외부 라이브러리에 의존하는 경우) `Sequence` 객체\n",
    "\n",
    "## `keras.utils.Sequence` 객체를 입력으로 사용하기\n",
    "\n",
    "`keras.utils.Sequence`는 두 가지 중요한 속성을 가진 Python 생성기를 얻기 위해 하위 클래스화를 수행할 수 있는 유틸리티입니다.\n",
    "\n",
    "- 멀티 프로세싱과 잘 작동합니다.\n",
    "- 셔플할 수 있습니다(예: `fit()`에서 `shuffle=True`를 전달하는 경우).\n",
    "\n",
    "`Sequence` 는 두 가지 방법을 구현해야합니다.\n",
    "\n",
    "- `__getitem__`\n",
    "- `__len__`\n",
    "\n",
    "`__getitem__` 메소드는 완전한 배치를 리턴해야합니다. 신기원 사이의 데이터 세트를 수정하려면 `on_epoch_end` 구현할 수 있습니다.\n",
    "\n",
    "간단한 예를 들자면 다음과 같습니다.\n",
    "\n",
    "```python\n",
    "from skimage.io import imread\n",
    "from skimage.transform import resize\n",
    "import numpy as np\n",
    "\n",
    "# Here, `filenames` is list of path to the images\n",
    "# and `labels` are the associated labels.\n",
    "\n",
    "class CIFAR10Sequence(Sequence):\n",
    "    def __init__(self, filenames, labels, batch_size):\n",
    "        self.filenames, self.labels = filenames, labels\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.filenames) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.filenames[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.labels[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        return np.array([\n",
    "            resize(imread(filename), (200, 200))\n",
    "               for filename in batch_x]), np.array(batch_y)\n",
    "\n",
    "sequence = CIFAR10Sequence(filenames, labels, batch_size)\n",
    "model.fit(sequence, epochs=10)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2a28343b1967"
   },
   "source": [
    "## 샘플 가중치 및 클래스 가중치 사용\n",
    "\n",
    "기본 설정을 사용하면 샘플의 무게가 데이터 세트의 빈도에 따라 결정됩니다. 샘플 빈도와 관계없이 데이터에 가중치를 부여하는 방법에는 두 가지가 있습니다.\n",
    "\n",
    "- 클래스 가중치\n",
    "- 샘플 무게"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f234a9a75b6d"
   },
   "source": [
    "### 클래스 가중치\n",
    "\n",
    "이 가중치는 `Model.fit()`에 대한 `class_weight` 인수로 사전을 전달하여 설정합니다. 이 사전은 클래스 인덱스를 이 클래스에 속한 샘플에 사용해야 하는 가중치에 매핑합니다.\n",
    "\n",
    "이 방법은 샘플링을 다시 수행하지 않고 클래스의 균형을 맞추거나 특정 클래스에 더 중요한 모델을 훈련시키는 데 사용할 수 있습니다.\n",
    "\n",
    "예를 들어, 데이터에서 클래스 \"0\"이 클래스 \"1\"로 표시된 것의 절반인 경우 `Model.fit(..., class_weight={0: 1., 1: 0.5})`을 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9929d26d91b8"
   },
   "source": [
    "다음은 클래스 #5(MNIST 데이터세트에서 숫자 \"5\")의 올바른 분류에 더 많은 중요성을 두도록 클래스 가중치 또는 샘플 가중치를 사용하는 NumPy 예입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:32.379985Z",
     "iopub.status.busy": "2021-04-07T17:59:32.379268Z",
     "iopub.status.idle": "2021-04-07T17:59:34.552093Z",
     "shell.execute_reply": "2021-04-07T17:59:34.552450Z"
    },
    "id": "f1844f2329a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit with class weight\n",
      "WARNING:tensorflow:From C:\\Users\\jikim\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3711 - sparse_categorical_accuracy: 0.9022\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1abf3129310>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "class_weight = {\n",
    "    0: 1.0,\n",
    "    1: 1.0,\n",
    "    2: 1.0,\n",
    "    3: 1.0,\n",
    "    4: 1.0,\n",
    "    # Set weight \"2\" for class \"5\",\n",
    "    # making this class 2x more important\n",
    "    5: 2.0,\n",
    "    6: 1.0,\n",
    "    7: 1.0,\n",
    "    8: 1.0,\n",
    "    9: 1.0,\n",
    "}\n",
    "\n",
    "print(\"Fit with class weight\")\n",
    "model = get_compiled_model()\n",
    "model.fit(x_train, y_train, class_weight=class_weight, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ce27221fad08"
   },
   "source": [
    "### 샘플 무게\n",
    "\n",
    "세밀한 제어를 위해 또는 분류기를 작성하지 않는 경우 \"샘플 가중치\"를 사용할 수 있습니다.\n",
    "\n",
    "- NumPy 데이터에서 학습하는 경우 : `sample_weight` 인수를 `Model.fit()` .\n",
    "- `tf.data` 또는 다른 종류의 반복자에서 훈련 할 때 : Yield `(input_batch, label_batch, sample_weight_batch)` 튜플.\n",
    "\n",
    "\"샘플 가중치\"배열은 배치에서 각 샘플이 총 손실을 계산하는 데 필요한 가중치를 지정하는 숫자 배열입니다. 불균형 분류 문제 (거의 보이지 않는 클래스에 더 많은 가중치를 부여하는 아이디어)에 일반적으로 사용됩니다.\n",
    "\n",
    "사용 된 가중치가 1과 0 인 경우, 어레이는 손실 함수에 대한 *마스크* 로 사용될 수 있습니다 (전체 손실에 대한 특정 샘플의 기여를 완전히 버림)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:34.557087Z",
     "iopub.status.busy": "2021-04-07T17:59:34.556528Z",
     "iopub.status.idle": "2021-04-07T17:59:41.179312Z",
     "shell.execute_reply": "2021-04-07T17:59:41.178824Z"
    },
    "id": "f9819d647793"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit with sample weight\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3808 - sparse_categorical_accuracy: 0.9000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1abf9592ac0>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_weight = np.ones(shape=(len(y_train),))\n",
    "sample_weight[y_train == 5] = 2.0\n",
    "\n",
    "print(\"Fit with sample weight\")\n",
    "model = get_compiled_model()\n",
    "model.fit(x_train, y_train, sample_weight=sample_weight, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eae5837c5f56"
   },
   "source": [
    "일치하는 `Dataset` 예는 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:41.184161Z",
     "iopub.status.busy": "2021-04-07T17:59:41.183589Z",
     "iopub.status.idle": "2021-04-07T17:59:43.788537Z",
     "shell.execute_reply": "2021-04-07T17:59:43.788025Z"
    },
    "id": "c870f3f0c66c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3782 - sparse_categorical_accuracy: 0.9011\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1abf95991f0>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_weight = np.ones(shape=(len(y_train),))\n",
    "sample_weight[y_train == 5] = 2.0\n",
    "\n",
    "# Create a Dataset that includes sample weights\n",
    "# (3rd element in the return tuple).\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train, sample_weight))\n",
    "\n",
    "# Shuffle and slice the dataset.\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "model = get_compiled_model()\n",
    "model.fit(train_dataset, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3963bfa348b0"
   },
   "source": [
    "## 다중 입력, 다중 출력 모델로 데이터 전달\n",
    "\n",
    "이전 예에서는 단일 입력(형상 `(764,)`의 텐서)과 단일 출력(형상 `(10,)`의 예측 텐서)이 있는 모델을 고려했습니다. 그렇다면 입력 또는 출력이 여러 개인 모델은 어떨까요?\n",
    "\n",
    "shape `(32, 32, 3)` ( `(height, width, channels)` 입력과 shape `(None, 10)` 의 시계열 입력 `(timesteps, features)` 하십시오. 우리의 모델은이 입력들의 조합으로부터 계산 된 두 개의 출력을 가질 것입니다 : \"점수\"(모양 `(1,)` )와 5 개의 클래스 (모양 `(5,)` )에 대한 확률 분포."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[ -13.047918     4.3807354   35.430634 ]\n",
      "  [ -26.06468     19.606457    49.634308 ]\n",
      "  [ -39.081432    34.832172    63.837982 ]\n",
      "  [ -52.09819     50.05789     78.04166  ]]\n",
      "\n",
      " [[ -91.14845     95.73506    120.65267  ]\n",
      "  [-104.165215   110.960785   134.85635  ]\n",
      "  [-117.18196    126.1865     149.06001  ]\n",
      "  [-130.19873    141.41223    163.2637   ]]], shape=(2, 4, 3), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(2*6*10).reshape(2,6,10)\n",
    "a = tf.constant(a, dtype=tf.float32)\n",
    "b = layers.Conv1D(3, 3)(a)  # (2,6,10)(3,10,3) => (2,4,3)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:43.798671Z",
     "iopub.status.busy": "2021-04-07T17:59:43.797137Z",
     "iopub.status.idle": "2021-04-07T17:59:43.836889Z",
     "shell.execute_reply": "2021-04-07T17:59:43.837258Z"
    },
    "id": "5f958449a057"
   },
   "outputs": [],
   "source": [
    "image_input = keras.Input(shape=(32, 32, 3), name=\"img_input\")\n",
    "timeseries_input = keras.Input(shape=(None, 10), name=\"ts_input\")\n",
    "\n",
    "x1 = layers.Conv2D(3, 3)(image_input)   # (None,32,32,3)(3,3,3,3)\n",
    "x1 = layers.GlobalMaxPooling2D()(x1)    # (None,30,30,3) \n",
    "                                        # (None,3)\n",
    "\n",
    "x2 = layers.Conv1D(3, 3)(timeseries_input)  # (None,None,10)(3,10,3)\n",
    "x2 = layers.GlobalMaxPooling1D()(x2)        # (None,None,3)\n",
    "                                            # (None,3)\n",
    "\n",
    "x = layers.concatenate([x1, x2])  # (None,3),(None,3)\n",
    "                                  # (None,6)\n",
    "\n",
    "score_output = layers.Dense(1, name=\"score_output\")(x)   # (None,6)(6,1)\n",
    "class_output = layers.Dense(5, name=\"class_output\")(x)   # (None,6)(6,5)\n",
    "\n",
    "model = keras.Model(\n",
    "    inputs=[image_input, timeseries_input], outputs=[score_output, class_output]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "df3ed34fe78b"
   },
   "source": [
    "이 모델을 플로팅하여 여기서 수행중인 작업을 명확하게 확인할 수 있습니다 (플롯에 표시된 셰이프는 샘플 별 셰이프가 아니라 배치 셰이프 임)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:43.841632Z",
     "iopub.status.busy": "2021-04-07T17:59:43.840966Z",
     "iopub.status.idle": "2021-04-07T17:59:43.997553Z",
     "shell.execute_reply": "2021-04-07T17:59:43.997939Z"
    },
    "id": "ac8c1baca9e3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.utils.plot_model(model, \"multi_input_and_output_model.png\", show_shapes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4d979e89b335"
   },
   "source": [
    "컴파일 타임에 손실 함수를 목록으로 전달하여 출력마다 다른 손실을 지정할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:44.008729Z",
     "iopub.status.busy": "2021-04-07T17:59:44.008083Z",
     "iopub.status.idle": "2021-04-07T17:59:44.020566Z",
     "shell.execute_reply": "2021-04-07T17:59:44.020024Z"
    },
    "id": "9655c0084d70"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss=[keras.losses.MeanSquaredError(), keras.losses.CategoricalCrossentropy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f5fc73405283"
   },
   "source": [
    "모델에 단일 손실 함수만 전달하는 경우, 모든 출력에 동일한 손실 함수가 적용됩니다(여기서는 적합하지 않음).\n",
    "\n",
    "메트릭의 경우도 마찬가지입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:44.031233Z",
     "iopub.status.busy": "2021-04-07T17:59:44.030430Z",
     "iopub.status.idle": "2021-04-07T17:59:44.054558Z",
     "shell.execute_reply": "2021-04-07T17:59:44.054914Z"
    },
    "id": "b4c0c6c564bc"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss=[keras.losses.MeanSquaredError(), keras.losses.CategoricalCrossentropy()],\n",
    "    metrics=[\n",
    "        [\n",
    "            keras.metrics.MeanAbsolutePercentageError(),\n",
    "            keras.metrics.MeanAbsoluteError(),\n",
    "        ],\n",
    "        [keras.metrics.CategoricalAccuracy()],\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4dd9fb0343cc"
   },
   "source": [
    "출력 레이어에 이름을 지정 했으므로 dict를 통해 출력 당 손실 및 메트릭을 지정할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:44.064527Z",
     "iopub.status.busy": "2021-04-07T17:59:44.063850Z",
     "iopub.status.idle": "2021-04-07T17:59:44.083742Z",
     "shell.execute_reply": "2021-04-07T17:59:44.083134Z"
    },
    "id": "42cb75110fc3"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss={\n",
    "        \"score_output\": keras.losses.MeanSquaredError(),\n",
    "        \"class_output\": keras.losses.CategoricalCrossentropy(),\n",
    "    },\n",
    "    metrics={\n",
    "        \"score_output\": [\n",
    "            keras.metrics.MeanAbsolutePercentageError(),\n",
    "            keras.metrics.MeanAbsoluteError(),\n",
    "        ],\n",
    "        \"class_output\": [keras.metrics.CategoricalAccuracy()],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bfd95ac0dd8b"
   },
   "source": [
    "출력이 두 개 이상인 경우 명시적 이름과 사전을 사용하는 것이 좋습니다.\n",
    "\n",
    "`loss_weights` 인수를 사용하여 출력별 손실에 서로 다른 가중치를 부여할 수 있습니다(예를 들어, 클래스 손실에 2x의 중요도를 부여하여 이 예에서 \"score\" 손실에 우선권을 줄 수 있음)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:44.093695Z",
     "iopub.status.busy": "2021-04-07T17:59:44.093100Z",
     "iopub.status.idle": "2021-04-07T17:59:44.112359Z",
     "shell.execute_reply": "2021-04-07T17:59:44.112739Z"
    },
    "id": "23a71e5f5227"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss={\n",
    "        \"score_output\": keras.losses.MeanSquaredError(),\n",
    "        \"class_output\": keras.losses.CategoricalCrossentropy(),\n",
    "    },\n",
    "    metrics={\n",
    "        \"score_output\": [\n",
    "            keras.metrics.MeanAbsolutePercentageError(),\n",
    "            keras.metrics.MeanAbsoluteError(),\n",
    "        ],\n",
    "        \"class_output\": [keras.metrics.CategoricalAccuracy()],\n",
    "    },\n",
    "    loss_weights={\"score_output\": 2.0, \"class_output\": 1.0},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "367f598029e7"
   },
   "source": [
    "이러한 출력이 예측 용이지만 훈련 용이 아닌 경우 특정 출력에 대한 손실을 계산하지 않도록 선택할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:44.121160Z",
     "iopub.status.busy": "2021-04-07T17:59:44.120554Z",
     "iopub.status.idle": "2021-04-07T17:59:44.130318Z",
     "shell.execute_reply": "2021-04-07T17:59:44.130734Z"
    },
    "id": "6d51aa372ef4"
   },
   "outputs": [],
   "source": [
    "# List loss version\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss=[None, keras.losses.CategoricalCrossentropy()],\n",
    ")\n",
    "\n",
    "# Or dict loss version\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss={\"class_output\": keras.losses.CategoricalCrossentropy()},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8314a8b3a7c7"
   },
   "source": [
    "적합하게 다중 입력 또는 다중 출력 모델에 데이터를 전달하는 것은 컴파일에서 손실 함수를 지정하는 것과 유사한 방식으로 작동합니다. **NumPy 배열 목록을** 전달할 수 있습니다 (손실 함수를 수신 한 출력에 1 : 1 매핑). **출력 이름을 NumPy 배열에 매핑합니다** ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:44.135391Z",
     "iopub.status.busy": "2021-04-07T17:59:44.134811Z",
     "iopub.status.idle": "2021-04-07T17:59:46.741893Z",
     "shell.execute_reply": "2021-04-07T17:59:46.742292Z"
    },
    "id": "0539da84328b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 18ms/step - loss: 5.8324 - score_output_loss: 0.1267 - class_output_loss: 5.7058\n",
      "4/4 [==============================] - 0s 8ms/step - loss: 4.6195 - score_output_loss: 0.1248 - class_output_loss: 4.4947\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ac162245b0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=keras.optimizers.RMSprop(1e-3),\n",
    "    loss=[keras.losses.MeanSquaredError(), keras.losses.CategoricalCrossentropy()],\n",
    ")\n",
    "\n",
    "# Generate dummy NumPy data\n",
    "img_data = np.random.random_sample(size=(100, 32, 32, 3))\n",
    "ts_data = np.random.random_sample(size=(100, 20, 10))\n",
    "score_targets = np.random.random_sample(size=(100, 1))\n",
    "class_targets = np.random.random_sample(size=(100, 5))\n",
    "\n",
    "# Fit on lists\n",
    "model.fit([img_data, ts_data], [score_targets, class_targets], batch_size=32, epochs=1)\n",
    "\n",
    "# Alternatively, fit on dicts\n",
    "model.fit(\n",
    "    {\"img_input\": img_data, \"ts_input\": ts_data},\n",
    "    {\"score_output\": score_targets, \"class_output\": class_targets},\n",
    "    batch_size=32,\n",
    "    epochs=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e53eda8e1399"
   },
   "source": [
    "`Dataset` 사용 사례는 다음과 같습니다. NumPy 배열에서 수행 한 것과 유사하게 `Dataset` 은 튜플 튜플을 반환해야합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:46.752664Z",
     "iopub.status.busy": "2021-04-07T17:59:46.752034Z",
     "iopub.status.idle": "2021-04-07T17:59:47.185670Z",
     "shell.execute_reply": "2021-04-07T17:59:47.186035Z"
    },
    "id": "4df41a12ed2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 5ms/step - loss: 22.7519 - score_output_loss: 0.1145 - class_output_loss: 22.6374\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13e0259ba00>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (\n",
    "        {\"img_input\": img_data, \"ts_input\": ts_data},\n",
    "        {\"score_output\": score_targets, \"class_output\": class_targets},\n",
    "    )\n",
    ")\n",
    "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(64)\n",
    "\n",
    "model.fit(train_dataset, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "38ebf30ce6ac"
   },
   "source": [
    "## 콜백 사용하기\n",
    "\n",
    "Keras의 콜백은 훈련 중 다른 시점(epoch의 시작, 배치의 끝, epoch의 끝 등)에서 호출되며 다음과 같은 동작을 구현하는 데 사용할 수 있는 객체입니다.\n",
    "\n",
    "- 훈련 중 서로 다른 시점에서 유효성 검사 수행(내장된 epoch당 유효성 검사에서 더욱 확장)\n",
    "- 정기적으로 또는 특정 정확도 임계값을 초과할 때 모델 검사점 설정\n",
    "- 훈련이 정체 된 것처럼 보일 때 모델의 학습 속도 변경\n",
    "- 훈련이 정체 된 것처럼 보일 때 최상위 레이어의 미세 조정\n",
    "- 교육이 종료되거나 특정 성능 임계 값을 초과 한 경우 전자 메일 또는 인스턴트 메시지 알림 보내기\n",
    "- 기타\n",
    "\n",
    "콜백은 `fit()` 에 대한 호출에 목록으로 전달 될 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:47.193545Z",
     "iopub.status.busy": "2021-04-07T17:59:47.192522Z",
     "iopub.status.idle": "2021-04-07T17:59:57.855887Z",
     "shell.execute_reply": "2021-04-07T17:59:57.855277Z"
    },
    "id": "15036ddbee42"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "625/625 [==============================] - 4s 6ms/step - loss: 0.3732 - sparse_categorical_accuracy: 0.8952 - val_loss: 0.2359 - val_sparse_categorical_accuracy: 0.9308\n",
      "Epoch 2/20\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.1772 - sparse_categorical_accuracy: 0.9480 - val_loss: 0.1969 - val_sparse_categorical_accuracy: 0.9411\n",
      "Epoch 3/20\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.1295 - sparse_categorical_accuracy: 0.9607 - val_loss: 0.1549 - val_sparse_categorical_accuracy: 0.9540\n",
      "Epoch 4/20\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.1036 - sparse_categorical_accuracy: 0.9683 - val_loss: 0.1459 - val_sparse_categorical_accuracy: 0.9586\n",
      "Epoch 5/20\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.0854 - sparse_categorical_accuracy: 0.9744 - val_loss: 0.1485 - val_sparse_categorical_accuracy: 0.9580\n",
      "Epoch 00005: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ac16232e20>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        # Stop training when `val_loss` is no longer improving\n",
    "        monitor=\"val_loss\",\n",
    "        # \"no longer improving\" being defined as \"no better than 1e-2 less\"\n",
    "        min_delta=1e-2,\n",
    "        # \"no longer improving\" being further defined as \"for at least 2 epochs\"\n",
    "        patience=2,\n",
    "        verbose=1,\n",
    "    )\n",
    "]\n",
    "model.fit(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    epochs=20,\n",
    "    batch_size=64,\n",
    "    callbacks=callbacks,\n",
    "    validation_split=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "303815509732"
   },
   "source": [
    "### 많은 내장 콜백을 사용할 수 있습니다\n",
    "\n",
    "- `ModelCheckpoint` : 주기적으로 모델을 저장합니다.\n",
    "- `EarlyStopping`: 훈련이 더 이상 유효성 검사 메트릭을 개선하지 못하는 경우 훈련을 중단합니다.\n",
    "- `TensorBoard` : 시각화 할 수 있습니다 정기적으로 쓰기 모델 로그 [TensorBoard](https://www.tensorflow.org/tensorboard) (섹션 \"시각화\"에서 자세한 내용).\n",
    "- `CSVLogger` : 손실 및 메트릭 데이터를 CSV 파일로 스트리밍합니다.\n",
    "- 기타\n",
    "\n",
    "전체 목록은 [콜백 설명서](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/) 를 참조하십시오.\n",
    "\n",
    "### 자신의 콜백 작성\n",
    "\n",
    "기본 클래스 `keras.callbacks.Callback` 을 확장하여 사용자 정의 콜백을 작성할 수 있습니다. 콜백은 클래스 속성 `self.model` 통해 연관된 모델에 액세스 할 수 있습니다.\n",
    "\n",
    "[사용자 정의 콜백을 작성하기 위한 전체 가이드](https://www.tensorflow.org/guide/keras/custom_callback/)를 꼭 읽어보세요. 다음은 훈련 중 배치별 손실 값 목록을 저장하는 간단한 예입니다.\n",
    "\n",
    "다음은 훈련 중 배치 별 손실 값 목록을 저장하는 간단한 예입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:57.860674Z",
     "iopub.status.busy": "2021-04-07T17:59:57.860106Z",
     "iopub.status.idle": "2021-04-07T17:59:57.862542Z",
     "shell.execute_reply": "2021-04-07T17:59:57.862070Z"
    },
    "id": "b265d36ce608"
   },
   "outputs": [],
   "source": [
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs):\n",
    "        self.per_batch_losses = []\n",
    "\n",
    "    def on_batch_end(self, batch, logs):\n",
    "        self.per_batch_losses.append(logs.get(\"loss\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5ee672524987"
   },
   "source": [
    "## 모델 검사점 설정하기\n",
    "\n",
    "상대적으로 큰 데이터세트에 대한 모델을 훈련시킬 때는 모델의 검사점을 빈번하게 저장하는 것이 중요합니다.\n",
    "\n",
    "이를 수행하는 가장 쉬운 방법은 `ModelCheckpoint` 콜백을 사용하는 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T17:59:57.870033Z",
     "iopub.status.busy": "2021-04-07T17:59:57.868836Z",
     "iopub.status.idle": "2021-04-07T18:00:02.043065Z",
     "shell.execute_reply": "2021-04-07T18:00:02.042601Z"
    },
    "id": "83614be57725"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "625/625 [==============================] - 4s 6ms/step - loss: 0.3709 - sparse_categorical_accuracy: 0.8956 - val_loss: 0.2298 - val_sparse_categorical_accuracy: 0.9316\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.22984, saving model to mymodel_1\n",
      "INFO:tensorflow:Assets written to: mymodel_1\\assets\n",
      "Epoch 2/2\n",
      "625/625 [==============================] - 3s 5ms/step - loss: 0.1791 - sparse_categorical_accuracy: 0.9480 - val_loss: 0.1746 - val_sparse_categorical_accuracy: 0.9474\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.22984 to 0.17464, saving model to mymodel_2\n",
      "INFO:tensorflow:Assets written to: mymodel_2\\assets\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ac232aa400>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = get_compiled_model()\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        # Path where to save the model\n",
    "        # The two parameters below mean that we will overwrite\n",
    "        # the current checkpoint if and only if\n",
    "        # the `val_loss` score has improved.\n",
    "        # The saved model name will include the current epoch.\n",
    "        filepath=\"mymodel_{epoch}\",\n",
    "        save_best_only=True,  # Only save a model if `val_loss` has improved.\n",
    "        monitor=\"val_loss\",\n",
    "        verbose=1,\n",
    "    )\n",
    "]\n",
    "model.fit(\n",
    "    x_train, y_train, epochs=2, batch_size=64, callbacks=callbacks, validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7f6afa36950c"
   },
   "source": [
    "`ModelCheckpoint` 콜백을 사용하여 내결함성을 구현할 수 있습니다. 훈련이 무작위로 중단 된 경우 모델의 마지막 저장된 상태에서 훈련을 다시 시작할 수있는 기능. 기본 예는 다음과 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T18:00:02.050845Z",
     "iopub.status.busy": "2021-04-07T18:00:02.048933Z",
     "iopub.status.idle": "2021-04-07T18:00:11.144699Z",
     "shell.execute_reply": "2021-04-07T18:00:11.144180Z"
    },
    "id": "27ce92b2ad58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a new model\n",
      "  93/1563 [>.............................] - ETA: 8s - loss: 0.9757 - sparse_categorical_accuracy: 0.7503INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.94\\assets\n",
      " 196/1563 [==>...........................] - ETA: 8s - loss: 0.7056 - sparse_categorical_accuracy: 0.8154INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.70\\assets\n",
      " 288/1563 [====>.........................] - ETA: 8s - loss: 0.6040 - sparse_categorical_accuracy: 0.8391INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.59\\assets\n",
      " 393/1563 [======>.......................] - ETA: 7s - loss: 0.5339 - sparse_categorical_accuracy: 0.8535INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.53\\assets\n",
      " 492/1563 [========>.....................] - ETA: 7s - loss: 0.4884 - sparse_categorical_accuracy: 0.8652INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.48\\assets\n",
      " 598/1563 [==========>...................] - ETA: 6s - loss: 0.4523 - sparse_categorical_accuracy: 0.8746INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.45\\assets\n",
      " 692/1563 [============>.................] - ETA: 6s - loss: 0.4283 - sparse_categorical_accuracy: 0.8798INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.43\\assets\n",
      " 795/1563 [==============>...............] - ETA: 5s - loss: 0.4051 - sparse_categorical_accuracy: 0.8857INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.40\\assets\n",
      " 890/1563 [================>.............] - ETA: 4s - loss: 0.3873 - sparse_categorical_accuracy: 0.8907INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.39\\assets\n",
      " 991/1563 [==================>...........] - ETA: 4s - loss: 0.3693 - sparse_categorical_accuracy: 0.8956INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.37\\assets\n",
      "1097/1563 [====================>.........] - ETA: 3s - loss: 0.3553 - sparse_categorical_accuracy: 0.8994INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.35\\assets\n",
      "1197/1563 [=====================>........] - ETA: 2s - loss: 0.3408 - sparse_categorical_accuracy: 0.9035INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.34\\assets\n",
      "1298/1563 [=======================>......] - ETA: 1s - loss: 0.3303 - sparse_categorical_accuracy: 0.9063INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.33\\assets\n",
      "1392/1563 [=========================>....] - ETA: 1s - loss: 0.3204 - sparse_categorical_accuracy: 0.9091INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.32\\assets\n",
      "1491/1563 [===========================>..] - ETA: 0s - loss: 0.3111 - sparse_categorical_accuracy: 0.9117INFO:tensorflow:Assets written to: ./ckpt\\ckpt-loss=0.31\\assets\n",
      "1563/1563 [==============================] - 12s 7ms/step - loss: 0.3044 - sparse_categorical_accuracy: 0.9136\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ac07467ca0>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Prepare a directory to store all the checkpoints.\n",
    "checkpoint_dir = \"./ckpt\"\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)\n",
    "\n",
    "\n",
    "def make_or_restore_model():\n",
    "    # Either restore the latest model, or create a fresh one\n",
    "    # if there is no checkpoint available.\n",
    "    checkpoints = [checkpoint_dir + \"/\" + name for name in os.listdir(checkpoint_dir)]\n",
    "    if checkpoints:\n",
    "        latest_checkpoint = max(checkpoints, key=os.path.getctime)\n",
    "        print(\"Restoring from\", latest_checkpoint)\n",
    "        return keras.models.load_model(latest_checkpoint)\n",
    "    print(\"Creating a new model\")\n",
    "    return get_compiled_model()\n",
    "\n",
    "\n",
    "model = make_or_restore_model()\n",
    "callbacks = [\n",
    "    # This callback saves a SavedModel every 100 batches.\n",
    "    # We include the training loss in the saved model name.\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=checkpoint_dir + \"/ckpt-loss={loss:.2f}\", save_freq=100\n",
    "    )\n",
    "]\n",
    "model.fit(x_train, y_train, epochs=1, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "da3ab58d5235"
   },
   "source": [
    "또한 모델 저장 및 복원을 위해 자체 콜백을 작성하십시오.\n",
    "\n",
    "직렬화 및 저장에 대한 전체 안내서는 [모델 저장 및 직렬화 안내서를](https://www.tensorflow.org/guide/keras/save_and_serialize/) 참조하십시오."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b9342cc2ddba"
   },
   "source": [
    "## 학습 속도 일정 사용하기\n",
    "\n",
    "딥 러닝 모델을 훈련 할 때 일반적인 패턴은 훈련이 진행됨에 따라 점차적으로 학습을 줄이는 것입니다. 이것을 일반적으로 \"학습률 감소\"라고합니다.\n",
    "\n",
    "학습 붕괴 스케줄은 정적 인 (현재 에포크 또는 현재 배치 인덱스의 함수로서 미리 고정됨) 또는 동적 (모델의 현재 행동, 특히 검증 손실에 대응) 일 수있다.\n",
    "\n",
    "### 옵티마이저로 일정 전달하기\n",
    "\n",
    "옵티 마이저에서 schedule 객체를 `learning_rate` 인수로 전달하여 정적 학습 속도 감소 스케줄을 쉽게 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T18:00:11.150053Z",
     "iopub.status.busy": "2021-04-07T18:00:11.149381Z",
     "iopub.status.idle": "2021-04-07T18:00:11.151800Z",
     "shell.execute_reply": "2021-04-07T18:00:11.151244Z"
    },
    "id": "684f0ab6d3de"
   },
   "outputs": [],
   "source": [
    "initial_learning_rate = 0.1\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate, decay_steps=100000, decay_rate=0.96, staircase=True\n",
    ")\n",
    "\n",
    "optimizer = keras.optimizers.RMSprop(learning_rate=lr_schedule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7d742e44f535"
   },
   "source": [
    "`ExponentialDecay` , `PiecewiseConstantDecay` , `PolynomialDecay` 및 `InverseTimeDecay` 와 같은 몇 가지 기본 제공 일정을 사용할 수 있습니다.\n",
    "\n",
    "### 콜백을 사용하여 동적 학습 속도 일정 구현\n",
    "\n",
    "옵티마이저가 유효성 검사 메트릭에 액세스할 수 없으므로 이러한 일정 객체로는 동적 학습률 일정(예: 유효성 검사 손실이 더 이상 개선되지 않을 때 학습률 감소)을 달성할 수 없습니다.\n",
    "\n",
    "그러나 콜백은 유효성 검사 메트릭을 포함해 모든 메트릭에 액세스할 수 있습니다! 따라서 옵티마이저에서 현재 학습률을 수정하는 콜백을 사용하여 이 패턴을 달성할 수 있습니다. 실제로 이 부분이`ReduceLROnPlateau` 콜백으로 내장되어 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b4a05f880175"
   },
   "source": [
    "## 훈련 중 손실 및 메트릭 시각화하기\n",
    "\n",
    "교육 중에 모델을 주시하는 가장 좋은 방법은 로컬에서 실행할 수있는 브라우저 기반 응용 프로그램 인 [TensorBoard](https://www.tensorflow.org/tensorboard) 를 사용하는 것입니다.\n",
    "\n",
    "- 교육 및 평가를위한 손실 및 지표의 라이브 플롯\n",
    "- (옵션) 레이어 활성화 히스토그램 시각화\n",
    "- (옵션) `Embedding` 레이어에서 학습한 포함된 공간의 3D 시각화\n",
    "\n",
    "pip와 함께 TensorFlow를 설치한 경우, 명령줄에서 TensorBoard를 시작할 수 있습니다.\n",
    "\n",
    "```\n",
    "tensorboard --logdir=/full_path_to_your_logs\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1fcf386a1dad"
   },
   "source": [
    "### TensorBoard 콜백 사용하기\n",
    "\n",
    "TensorBoard를 Keras 모델 및 fit 메서드와 함께 사용하는 가장 쉬운 방법은 `TensorBoard` 콜백입니다.\n",
    "\n",
    "가장 간단한 경우로, 콜백에서 로그를 작성할 위치만 지정하면 바로 쓸 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-07T18:00:11.157400Z",
     "iopub.status.busy": "2021-04-07T18:00:11.156688Z",
     "iopub.status.idle": "2021-04-07T18:00:11.159760Z",
     "shell.execute_reply": "2021-04-07T18:00:11.159192Z"
    },
    "id": "f74247282ff6"
   },
   "outputs": [],
   "source": [
    "keras.callbacks.TensorBoard(\n",
    "    log_dir=\"/full_path_to_your_logs\",\n",
    "    histogram_freq=0,  # How often to log histogram visualizations\n",
    "    embeddings_freq=0,  # How often to log embedding visualizations\n",
    "    update_freq=\"epoch\",\n",
    ")  # How often to write logs (default: once per epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "50cd5f8631fd"
   },
   "source": [
    "자세한 내용 [`TensorBoard` 콜백 설명서](https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/tensorboard/)를 참조하세요."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "train_and_evaluate.ipynb",
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
